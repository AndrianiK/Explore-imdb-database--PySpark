{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Analytics - Practical Exam 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24600a6e-84d7-4ff9-b591-7b138fc4f54c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Six Degrees of Kevin Bacon\n",
    "**Introduction** - Six Degrees of Kevin Bacon is a game based on the \"six degrees of separation\"\n",
    "concept, which posits that any two people on Earth are six or fewer acquaintance links apart. Movie\n",
    "buffs challenge each other to find the shortest path between an arbitrary actor and prolific actor\n",
    "Kevin Bacon. It rests on the assumption that anyone involved in the film industry can be linked\n",
    "through their film roles to Bacon within six steps.\n",
    "The analysis of social networks can be a computationally intensive task, especially when dealing with\n",
    "large volumes of data. It is also a challenging problem to devise a correct methodology to infer an\n",
    "informative social network structure. Here, we will analyze a social network of actors and actresses\n",
    "that co-participated in movies. We will do some simple descriptive analysis, and in the end try to\n",
    "relate an actor/actress’s position in the social network with the success of the movies in which they\n",
    "participate.\n",
    "\n",
    "#### Rules & Notes - Please take your time to read the following points:\n",
    "\n",
    "1. The submission deadline shall be set for the 10th of June at 23:59.\n",
    "2. It is acceptable that you **discuss** with your colleagues different approaches to solve each step of the problem set. You are responsible for writing your own code, and analysing the results. Clear cases of cheating will be penalized with 0 points in this assignment;\n",
    "3. After review of your submission files, and before a mark is attributed, you might be called to orally defend your submission;\n",
    "4. You will be scored first and foremost by the number of correct answers, secondly by the logic used in the trying to approach each step of the problem set;\n",
    "5. Consider skipping questions that you are stuck in, and get back to them later;\n",
    "6. Expect computations to take a few minutes to finish in some of the steps.\n",
    "7. **IMPORTANT** It is expected you have developed skills beyond writting SQL queries. Any question where you directly write a SQL query (then for example create a temporary table and use spark.sql to pass the query) will receive a 25% penalty. Using the Spark syntax (for example dataframe.select(\"\\*\").where(\"conditions\")) is acceptable and does not incur this penalty. Comment your code in a reasonable fashion.\n",
    "8. **Questions** – Any questions about this assignment should be posted in the Forum@Moodle. The last class will be an open office session for anyone with questions concerning the assignment. \n",
    "9. **Delivery** - To fulfil this activity you will have to upload the following materials to Moodle:\n",
    "    1. An exported IPython notebook. The notebook should be solved (have results displayed), but should contain all neccesary code so that when the notebook is run in databricks it should also replicate these results. This means the all data downloading and processing should be done in this notebook. It is also important you clearly indicate where your final answer to each question is when you are using multiple cells (for example you print \"my final anwser is\" before your answer or use cell comments). Please make sure to name your file in the following way: *[student_number1]_[student_number2]_submission.ipynb*. As an example: *19740001_197400010_submission.ipynb*\n",
    "    2. **Delivery** - You will also need to provide a signed statement of authorship, which is present in the last page;\n",
    "    3. It is recommended you read the whole assignment before starting.\n",
    "    4. You can add as many cells as you like to answer the questions.\n",
    "    5. You can make use of caching or persisting your RDDs or Dataframes, this may speed up performance.\n",
    "    6. If you have trouble with graphframes in databricks (specifically the import statement) you need to make sure the graphframes package is installed on the cluster you are running. If you click home on the left, then click on the graphframes library, from where you can install the package on your cluster (check the graphframes checkbox and click install). Another installation option is using the JAR available on Moodle with the graphframes library.\n",
    "10. **Note**: By including the name and student number of each group member  in the submission notebook, this will be considered as a declaration of authorship.\n",
    "\n",
    "#### Data Sources and Description\n",
    "We will use data from IMDB. You can download raw datafiles\n",
    "from https://datasets.imdbws.com. Note that the files are tab delimited (.tsv) You can find a\n",
    "description of the each datafile in https://www.imdb.com/interfaces/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39827279-2cb4-46ad-a17b-6d10a9c574f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Questions\n",
    "### Data loading and preperation\n",
    "Review the file descriptions and load the necessary data onto your databricks cluser and into spark dataframes. You will need to use shell commands to download the data, unzip the data, load the data into spark. Note that the data might require parsing and preprocessing to be ready for the questions below.\n",
    "\n",
    "**Hints** You can use 'gunzip' to unzip the .tz files. The data files will then be tab seperated (.tsv), which you can load into a dataframe using the tab seperated option instead of the comma seperated option we have typically used in class: `.option(“sep”,”\\t”)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5769a7-fd6c-4d0f-84c5-436cde5143e4",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from graphframes import GraphFrame\n",
    "\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load IMDB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec2e49ba-dc3e-4af7-822c-88915ed5281d",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "wget -P /tmp https://datasets.imdbws.com/name.basics.tsv.gz\n",
    "wget -P /tmp https://datasets.imdbws.com/title.basics.tsv.gz\n",
    "wget -P /tmp https://datasets.imdbws.com/title.principals.tsv.gz\n",
    "wget -P /tmp https://datasets.imdbws.com/title.ratings.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Copy loaded data to DBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95338ddd-0251-4012-ae90-ebee73b0ac0e",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.cp('file:/tmp/name.basics.tsv.gz', 'dbfs:/FileStore/tables/')\n",
    "dbutils.fs.cp('file:/tmp/title.basics.tsv.gz', 'dbfs:/FileStore/tables/')\n",
    "dbutils.fs.cp('file:/tmp/title.principals.tsv.gz', 'dbfs:/FileStore/tables/')\n",
    "dbutils.fs.cp('file:/tmp/title.ratings.tsv.gz', 'dbfs:/FileStore/tables/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load the data in dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "505b2487-f142-4aa0-92ac-93cd4a176132",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "title_basics_df = spark.read \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \"\\t\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .csv(\"/FileStore/tables/title.basics.tsv.gz\")\n",
    "\n",
    "title_principals_df = spark.read \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \"\\t\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .csv(\"/FileStore/tables/title.principals.tsv.gz\")\n",
    "\n",
    "title_ratings_df = spark.read \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \"\\t\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .csv(\"/FileStore/tables/title.ratings.tsv.gz\")\n",
    "\n",
    "name_basics_df = spark.read \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"sep\", \"\\t\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .csv(\"/FileStore/tables/name.basics.tsv.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data Exploration on dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9631ce2-8ab0-41cd-8bdd-62d894323cd9",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+-------------+-------+---------+-------+--------------+-----------------+\n",
      "|   tconst|titleType|primaryTitle|originalTitle|isAdult|startYear|endYear|runtimeMinutes|           genres|\n",
      "+---------+---------+------------+-------------+-------+---------+-------+--------------+-----------------+\n",
      "|tt0000001|    short|  Carmencita|   Carmencita|      0|     1894|     \\N|             1|Documentary,Short|\n",
      "+---------+---------+------------+-------------+-------+---------+-------+--------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- titleType: string (nullable = true)\n",
      " |-- primaryTitle: string (nullable = true)\n",
      " |-- originalTitle: string (nullable = true)\n",
      " |-- isAdult: string (nullable = true)\n",
      " |-- startYear: string (nullable = true)\n",
      " |-- endYear: string (nullable = true)\n",
      " |-- runtimeMinutes: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_basics_df.show(1)\n",
    "title_basics_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cae2e7ec-6e32-4ce5-9506-baa3267e5938",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "title_basics_df = title_basics_df \\\n",
    "  .withColumn(\"isAdult\", F.col(\"isAdult\").cast(\"integer\")) \\\n",
    "  .withColumn(\"startYear\", F.col(\"startYear\").cast(\"integer\")) \\\n",
    "  .withColumn(\"endYear\", F.col(\"endYear\").cast(\"integer\")) \\\n",
    "  .withColumn(\"runtimeMinutes\", F.col(\"runtimeMinutes\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "346fceae-6971-4e07-a32a-05aea6bed4ea",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+--------+---+----------+\n",
      "|   tconst|ordering|   nconst|category|job|characters|\n",
      "+---------+--------+---------+--------+---+----------+\n",
      "|tt0000001|       1|nm1588970|    self| \\N|  [\"Self\"]|\n",
      "+---------+--------+---------+--------+---+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- ordering: integer (nullable = true)\n",
      " |-- nconst: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- characters: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_principals_df.show(1)\n",
    "title_principals_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b292df68-ebff-46aa-9b03-79abdb47826e",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.7|    2059|\n",
      "+---------+-------------+--------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- averageRating: double (nullable = true)\n",
      " |-- numVotes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_ratings_df.show(1)\n",
    "title_ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33a41bd9-c2e4-43e9-8e34-57dc3793733f",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------+---------+--------------------+--------------------+\n",
      "|   nconst| primaryName|birthYear|deathYear|   primaryProfession|      knownForTitles|\n",
      "+---------+------------+---------+---------+--------------------+--------------------+\n",
      "|nm0000001|Fred Astaire|     1899|     1987|actor,miscellaneo...|tt0072308,tt00504...|\n",
      "+---------+------------+---------+---------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- nconst: string (nullable = true)\n",
      " |-- primaryName: string (nullable = true)\n",
      " |-- birthYear: string (nullable = true)\n",
      " |-- deathYear: string (nullable = true)\n",
      " |-- primaryProfession: string (nullable = true)\n",
      " |-- knownForTitles: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name_basics_df.show(1)\n",
    "name_basics_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87105645-a4a9-4c09-86fe-14aed7140d55",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "name_basics_df = name_basics_df \\\n",
    "  .withColumn(\"birthYear\", F.col(\"birthYear\").cast(\"integer\")) \\\n",
    "  .withColumn(\"deathYear\", F.col(\"deathYear\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save dataframes as parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "title_basics_df.write.parquet(\"/FileStore/tables/parquet/title_basics_df.parquet\")\n",
    "\n",
    "title_principals_df.write.parquet(\"/FileStore/tables/parquet/title_principals_df.parquet\")\n",
    "\n",
    "title_ratings_df.write.parquet(\"/FileStore/tables/parquet/title_ratings_df.parquet\")\n",
    "\n",
    "name_basics_df.write.parquet(\"/FileStore/tables/parquet/name_basics.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Reload the saved dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "title_basics_df = spark.read.parquet(\"/FileStore/tables/parquet/title_basics_df.parquet\")\n",
    "\n",
    "title_principals_df = spark.read.parquet(\"/FileStore/tables/parquet/title_principals_df.parquet\")\n",
    "\n",
    "title_ratings_df = spark.read.parquet(\"/FileStore/tables/parquet/title_ratings_df.parquet\")\n",
    "\n",
    "name_basics_df = spark.read.parquet(\"/FileStore/tables/parquet/name_basics.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d23201f4-8f5d-413d-a9ae-33e3d6d60cc6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Network Inference, Let’s build a network\n",
    "In the following questions you will look to summarise the data and build a network. We want to examine a network that abstracts how actors and actress are related through their co-participation in movies. To that end perform the following steps:\n",
    "\n",
    "**Q1** Create a DataFrame that combines **all the information** on each of the titles (i.e., movies, tv-shows, etc …) and **all of the information** the participants in those movies (i.e., actors, directors, etc … ), make sure the actual names of the movies and participants are included. It may be worth reviewing the following questions to see how this dataframe will be used.\n",
    "\n",
    "How many rows does your dataframe have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f804fcc4-1f8f-4315-a775-0c0e3a00e31d",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tconst: string, nconst: string, titleType: string, primaryTitle: string, originalTitle: string, isAdult: int, startYear: int, endYear: int, runtimeMinutes: int, genres: string, ordering: int, category: string, job: string, characters: string, primaryName: string, birthYear: int, deathYear: int, primaryProfession: string, knownForTitles: string, averageRating: double, numVotes: int]"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We combine the dataframes df_title_principals + df_title_basics + df_name_basics + df_title_ratings(for later use)\n",
    "# [no akas, no episode, no crew] as we'll not be using them later\n",
    "# example use:\n",
    "# -for Q2: title_principals, title_basics, name_basics\n",
    "# -for Q9: title_ratings\n",
    "\n",
    "# left join on title basics\n",
    "network_df = title_basics_df \\\n",
    "  .join(title_principals_df, \"tconst\", \"left\") \\\n",
    "  .join(name_basics_df, \"nconst\", \"left\") \\\n",
    "  .join(title_ratings_df, \"tconst\", \"left\")\n",
    "\n",
    "network_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f446dc5b-e076-4266-80e3-6eca2b9caecf",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- nconst: string (nullable = true)\n",
      " |-- titleType: string (nullable = true)\n",
      " |-- primaryTitle: string (nullable = true)\n",
      " |-- originalTitle: string (nullable = true)\n",
      " |-- isAdult: integer (nullable = true)\n",
      " |-- startYear: integer (nullable = true)\n",
      " |-- endYear: integer (nullable = true)\n",
      " |-- runtimeMinutes: integer (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- ordering: integer (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- characters: string (nullable = true)\n",
      " |-- primaryName: string (nullable = true)\n",
      " |-- birthYear: integer (nullable = true)\n",
      " |-- deathYear: integer (nullable = true)\n",
      " |-- primaryProfession: string (nullable = true)\n",
      " |-- knownForTitles: string (nullable = true)\n",
      " |-- averageRating: double (nullable = true)\n",
      " |-- numVotes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c29cf536-c556-44f1-8b62-b38a610e0ab8",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87295049"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "589aa907-059d-42af-a691-fb03f58ea0f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q1 ANSWER: the created dataframe has *87295049* rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82e468c2-355b-49a4-9091-6ff3c459a2c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Q2** Create a new DataFrame based on the previous step, with the following removed:\n",
    "1. Any participant that is not an actor or actress (as measured by the category column);\n",
    "1. All adult movies;\n",
    "1. All dead actors or actresses;\n",
    "1. All actors or actresses born before 1920 or with no date of birth listed;\n",
    "1. All titles that are not of the type movie.\n",
    "\n",
    "How many rows does your dataframe have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96cfc442-a01d-4be0-bd8e-0f7396fc12d2",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930743\n"
     ]
    }
   ],
   "source": [
    "network_filtered_df = network_df \\\n",
    "  .filter((F.col(\"category\") == \"actor\") | (F.col(\"category\") == \"actress\")) \\\n",
    "  .filter(F.col(\"isAdult\") == 0) \\\n",
    "  .filter(F.col(\"deathYear\").isNull()) \\\n",
    "  .filter(F.col(\"birthYear\") >= 1920) \\\n",
    "  .filter(F.col(\"titleType\") == \"movie\")\n",
    "\n",
    "network_filtered_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87bb50cb-4a7d-423d-9d5d-a18bcef4dc6f",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930743\n"
     ]
    }
   ],
   "source": [
    "print(network_filtered_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "150bc403-aab9-4da8-992d-ccca2baa1cfc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q2 ANSWER: the created dataframe has *930743* rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cac5a4e3-37c5-4325-93f9-9289ca25f609",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Q3** Convert the above Dataframe to an RDD. Use map and reduce to create a paired RDD which counts how many movies each actor / actress appears in.\n",
    "\n",
    "Display names of the top 10 actors/actresses according to the number of movies in which they appeared. Be careful to deal with different actors / actresses with the same name, these could be different people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1d1cb7e-ceeb-4191-b17d-783d1d80ac67",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# convert DataFrame to RDD\n",
    "network_filtered_rdd = network_filtered_df.rdd\n",
    "\n",
    "# *using 'nconst' instead of 'primaryName' in order to avoid losing info due to actors/actresses with the same name\n",
    "# pair RDD | count appearances of each actor/actress\n",
    "movies_count_df = network_filtered_rdd \\\n",
    "  .map(lambda r: (r[\"nconst\"], 1)) \\\n",
    "  .reduceByKey(lambda a, b: a + b) \\\n",
    "  .toDF([\"nconst\", \"movie_count\"])\n",
    "# sort from top movie count\n",
    "actors_raking_df = movies_count_df \\\n",
    "  .join(name_basics_df, \"nconst\") \\\n",
    "  .orderBy(F.col(\"movie_count\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b3ef16a-9765-4b71-b223-2cff5ab93908",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|      primaryName|movie_count|\n",
      "+-----------------+-----------+\n",
      "|     Brahmanandam|       1130|\n",
      "|Jagathy Sreekumar|        659|\n",
      "|    Shakti Kapoor|        600|\n",
      "|     Eric Roberts|        492|\n",
      "|      Aruna Irani|        467|\n",
      "|           Nassar|        440|\n",
      "|        Mammootty|        437|\n",
      "|            Helen|        433|\n",
      "|Tanikella Bharani|        412|\n",
      "|      Anupam Kher|        409|\n",
      "+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the names of the top 10 actors/actresses based on movie count\n",
    "actors_raking_df \\\n",
    "  .limit(10) \\\n",
    "  .select(\"primaryName\", \"movie_count\") \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3 ANSWER: top 10 actors/actresses (according to the number of movies in which they appeared):\n",
    "\n",
    "|      primaryName|movie_count|\n",
    "|-----------------|-----------|\n",
    "|     Brahmanandam|       1130|\n",
    "|Jagathy Sreekumar|        659|\n",
    "|    Shakti Kapoor|        600|\n",
    "|     Eric Roberts|        492|\n",
    "|      Aruna Irani|        467|\n",
    "|           Nassar|        440|\n",
    "|        Mammootty|        437|\n",
    "|            Helen|        433|\n",
    "|Tanikella Bharani|        412|\n",
    "|      Anupam Kher|        409|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e440ede-62e5-4ad4-8f32-745453eb75ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Q4** Start with the dataframe from Q2. Generate a DataFrame that lists all links of your network. Here we shall consider that a link connects a pair of actors/actresses if they participated in at least one movie together (actors / actresses should be represented by their unique ID's). For every link we then need anytime a pair of actors were together in a movie as a link in each direction (A -> B and B -> A). However links should be distinct we do not need duplicates when two actors worked together in several movies. \n",
    "\n",
    "Display a DataFrame with the first 10 edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5925857-0170-4840-99b7-0dd88acb4010",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# select columns of title-id and name-id \n",
    "work_links_df = network_filtered_df.select(\"tconst\", \"nconst\")\n",
    "\n",
    "# perform a self-join to find links (=pairs of actors/actresses who participated in the same movie)\n",
    "pairs_df = work_links_df \\\n",
    "  .alias(\"a\") \\\n",
    "  .join(work_links_df.alias(\"b\"), \"tconst\") \\\n",
    "  .filter(F.col(\"a.nconst\") < F.col(\"b.nconst\"))\n",
    "\n",
    "# create a union and drop the duplicates\n",
    "bd_pairs_df = pairs_df \\\n",
    "  .select(F.col(\"a.nconst\").alias(\"actor1\"), F.col(\"b.nconst\").alias(\"actor2\")) \\\n",
    "  .union(pairs_df.select(F.col(\"b.nconst\").alias(\"actor1\"), F.col(\"a.nconst\").alias(\"actor2\"))) \\\n",
    "  .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ff8d799-68bc-47a6-b8c8-e382d5a0fde7",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|   actor1|   actor2|\n",
      "+---------+---------+\n",
      "|nm0344892|nm1625681|\n",
      "|nm0241222|nm0991758|\n",
      "|nm0045119|nm0222426|\n",
      "|nm0000420|nm1249052|\n",
      "|nm0001857|nm3571592|\n",
      "|nm0578935|nm0723172|\n",
      "|nm0041517|nm0350208|\n",
      "|nm0028846|nm1940584|\n",
      "|nm0059077|nm0109386|\n",
      "|nm0972598|nm5000434|\n",
      "+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display first 10 pairs\n",
    "bd_pairs_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55371e97-bb7e-4b32-9b93-1dc2dde5e836",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q4 ANSWER: 10 first pairs of actors/actresses who participated in the same movie in the dataframe 'bd_pairs_df'\n",
    "\n",
    "\n",
    "| nconst     | nconst     |\n",
    "|------------|------------|\n",
    "|nm0344892|nm1625681|\n",
    "|nm0241222|nm0991758|\n",
    "|nm0045119|nm0222426|\n",
    "|nm0000420|nm1249052|\n",
    "|nm0001857|nm3571592|\n",
    "|nm0578935|nm0723172|\n",
    "|nm0041517|nm0350208|\n",
    "|nm0028846|nm1940584|\n",
    "|nm0059077|nm0109386|\n",
    "|nm0972598|nm5000434|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd6e0c4e-0fb0-4c61-947f-39d63fdf27cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Q5** Compute the page rank of each actor. This can be done using GraphFrames or\n",
    "by using RDDs and the iterative implementation of the PageRank algorithm. Do not take\n",
    "more than 5 iterations and use reset probility = 0.1.\n",
    "\n",
    "List the top 10 actors / actresses by pagerank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Install graphframes library: clusters -> click on working cluster -> \"Libraries\" tab -> \"Install New\" -> \"Maven\" -> in coordinates enter <br> '**graphframes:graphframes:0.8.1-spark3.0-s_2.12**' -> install*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60c5bc75-6665-4bf9-83fd-4331304621d8",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# using GraphFrames #\n",
    "\n",
    "# parameters:\n",
    "# reset_probability = 0.1\n",
    "# iterations = 5\n",
    "# using dataframe from Q4\n",
    "\n",
    "# create vertices df with distinct actors/actresses\n",
    "vertices_df = network_filtered_df \\\n",
    "  .select(\"nconst\", \"primaryName\") \\\n",
    "  .distinct() \\\n",
    "  .withColumnRenamed(\"nconst\", \"id\") # required by GraphFrame library\n",
    "# create edges df with links between actors/actresses\n",
    "edges_df = bd_pairs_df.select(\n",
    "  F.col(\"actor1\").alias(\"src\"),\n",
    "  F.col(\"actor2\").alias(\"dst\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc48680-5d75-48e1-90b1-ccd607e48023",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/dataframe.py:180: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n",
      "/databricks/spark/python/pyspark/sql/dataframe.py:159: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    }
   ],
   "source": [
    "# graphframe\n",
    "graph = GraphFrame(vertices_df, edges_df)\n",
    "#compute pagerank\n",
    "pagerank_results = graph.pageRank(resetProbability=0.1, maxIter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "151948cc-8f15-421a-ab94-cf2d4d788560",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# getting the top 10 actors/actresses by PageRank\n",
    "top_actors = pagerank_results.vertices \\\n",
    "  .orderBy(F.col(\"pagerank\").desc()) \\\n",
    "  .limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b72502-d087-4ae2-8713-f377b9e28252",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+------------------+\n",
      "|       id|     primaryName|          pagerank|\n",
      "+---------+----------------+------------------+\n",
      "|nm0000616|    Eric Roberts| 63.18792464931231|\n",
      "|nm0000514|  Michael Madsen| 34.07127419751417|\n",
      "|nm0001803|     Danny Trejo| 26.68548298873733|\n",
      "|nm0202966|     Keith David|24.948370778119802|\n",
      "|nm0001595|    Michael Paré| 24.44215091221613|\n",
      "|nm0261724|     Joe Estevez|23.999657624728556|\n",
      "|nm0726223|  Richard Riehle|23.060298350193882|\n",
      "|nm0000532|Malcolm McDowell| 22.96604219239015|\n",
      "|nm0442207|   Lloyd Kaufman|22.866559524956568|\n",
      "|nm0000448| Lance Henriksen|22.373924174702854|\n",
      "+---------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display\n",
    "top_actors.select(\"id\", \"primaryName\", \"pagerank\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5 ANSWER: The 10 most influential actors/actresses within the IMDb network (pagerank) :\n",
    "\n",
    "\n",
    "|id          |primaryName |pagerank    |\n",
    "|------------|------------|------------|\n",
    "|nm0000616|    Eric Roberts| 63.18792464931231|\n",
    "|nm0000514|  Michael Madsen| 34.07127419751417|\n",
    "|nm0001803|     Danny Trejo| 26.68548298873733|\n",
    "|nm0202966|     Keith David|24.948370778119802|\n",
    "|nm0001595|    Michael Paré| 24.44215091221613|\n",
    "|nm0261724|     Joe Estevez|23.999657624728556|\n",
    "|nm0726223|  Richard Riehle|23.060298350193882|\n",
    "|nm0000532|Malcolm McDowell| 22.96604219239015|\n",
    "|nm0442207|   Lloyd Kaufman|22.866559524956568|\n",
    "|nm0000448| Lance Henriksen|22.373924174702854|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebfc5b76-2ccf-4318-a655-f48fd047cedb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Q6**: Create an RDD with the number of outDegrees for each actor. Display the top 10 by outdegrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c66d509d-bdae-4244-b6fd-2e92929e3975",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# from graphframe of Q5\n",
    "out_degrees = graph.outDegrees\n",
    "# sorting actors/actresses by outDegree\n",
    "out_degrees_rdd = out_degrees.rdd \\\n",
    "  .map(lambda r: (r[\"id\"], r[\"outDegree\"])) \\\n",
    "  .sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "385da46e-daa6-4e66-953f-62c7f720466b",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nm0000616', 1337), ('nm0000514', 841), ('nm0451600', 760), ('nm0202966', 707), ('nm0410902', 703), ('nm0621937', 688), ('nm0000367', 677), ('nm0001803', 663), ('nm0256628', 658), ('nm0695177', 648)]\n"
     ]
    }
   ],
   "source": [
    "print(out_degrees_rdd.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6 ANSWER: The 10 actors/actresses based on the number of collaborations (movies) they've been involved (outdegrees):\n",
    "\n",
    "|       id|outDegree|\n",
    "|---------|---------|\n",
    "|nm0000616|     1337|\n",
    "|nm0000514|      841|\n",
    "|nm0451600|      760|\n",
    "|nm0202966|      706|\n",
    "|nm0410902|      703|\n",
    "|nm0621937|      688|\n",
    "|nm0000367|      676|\n",
    "|nm0001803|      663|\n",
    "|nm0256628|      658|\n",
    "|nm0695177|      648|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a15dc25-3e0f-4400-9207-127bcfdaee1f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Let’s play Kevin’s own game\n",
    "\n",
    "**Q7** Start with the graphframe / dataframe you developed in the previous questions. Using Spark GraphFrame and/or Spark Core library perform the following steps:\n",
    "\n",
    "1. Identify the id of Kevin Bacon, there are two actors named ‘Kevin Bacon’, we will use the one with the highest degree, that is, the one that participated in most titles;\n",
    "1. Estimate the shortest path between every actor in the database actors and Kevin Bacon, keep a dataframe with this information as you will need it later;\n",
    "1. Summarise the data, that is, count the number of actors at each number of degress from kevin bacon (you will need to deal with actors unconnected to kevin bacon, if not connected to Kevin Bacon given these actors / actresses a score/degree of 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68593435-ced4-46d1-b65b-28c78b2726b2",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#### 1 ####\n",
    "# getting id of Kevin Bacon by filtering names and sorting outdegrees\n",
    "kevin_bacon_id = vertices_df \\\n",
    "  .filter((F.col(\"primaryName\") == \"Kevin Bacon\")) \\\n",
    "  .join(out_degrees, vertices_df.id == out_degrees.id) \\\n",
    "  .orderBy(F.col(\"outDegree\").desc()) \\\n",
    "  .first()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6f3f606-ba47-4d99-8fb6-585daaea6a4d",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/dataframe.py:159: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    }
   ],
   "source": [
    "#### 2 ####\n",
    "# creating a dataframe with the shortest paths between every actor and Kevin Bacon\n",
    "shortest_paths = graph.shortestPaths(landmarks=[kevin_bacon_id])\n",
    "\n",
    "distances_df = shortest_paths \\\n",
    "  .select(\"id\", F.explode(\"distances\") \\\n",
    "  .alias(\"landmark\", \"distance\")) \\\n",
    "  .filter(F.col(\"landmark\") == kevin_bacon_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f35cdd2-e6ac-440d-bb9d-16aa8e1296c1",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#### 3 ####\n",
    "distances_df = distances_df \\\n",
    "  .withColumn(\"distance\", F.col(\"distance\").cast(\"int\"))\n",
    "\n",
    "all_actors_df = vertices_df \\\n",
    "  .select(F.col(\"id\") \\\n",
    "  .alias(\"actor_id\"))\n",
    "\n",
    "# joining id and distance of actor/actress\n",
    "distances_df = all_actors_df \\\n",
    "  .join(distances_df, all_actors_df.actor_id == distances_df.id, \"left_outer\") \\\n",
    "  .drop(\"id\")\n",
    "\n",
    "# impute value 20 for actors with no connection to Kevin Bacon\n",
    "distances_df = distances_df.na.fill({\"distance\": 20})\n",
    "\n",
    "# number of actors with each distance, sorted by distance\n",
    "summary_df = distances_df \\\n",
    "  .groupBy(\"distance\") \\\n",
    "  .count() \\\n",
    "  .orderBy(\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9452ca6-87d6-410c-a1d8-9c5a862cd86b",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|distance|count|\n",
      "+--------+-----+\n",
      "|       0|    1|\n",
      "|       1|  354|\n",
      "|       2|14170|\n",
      "|       3|58562|\n",
      "|       4|42460|\n",
      "|       5| 4842|\n",
      "|       6|  510|\n",
      "|       7|   56|\n",
      "|       8|   20|\n",
      "|       9|    3|\n",
      "|      20|15329|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7 ANSWER: \n",
    "1) Stored in 'kevin_bacon_id'\n",
    "\n",
    "2) Created: 'df_shortest_paths'\n",
    "\n",
    "3) \n",
    "|distances|count|\n",
    "|---------|-----|\n",
    "|       0|    1|\n",
    "|       1|  354|\n",
    "|       2|14170|\n",
    "|       3|58562|\n",
    "|       4|42460|\n",
    "|       5| 4842|\n",
    "|       6|  510|\n",
    "|       7|   56|\n",
    "|       8|   20|\n",
    "|       9|    3|\n",
    "|      20|15329|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72a70135-807b-4130-840e-d5df28102136",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exploring the data with RDD's\n",
    "\n",
    "Using RDDs and (not dataframes) answer the following questions (if you loaded your data into spark in a dataframe you can convert to an RDD of rows easily using `.rdd`):\n",
    "\n",
    "**Q8** Movies can have multiple genres. Considering only titles of the type 'movie' what is the combination of genres that is the most popluar (as measured by number of reviews). Hint: paired RDD's will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16a8e538-bb86-4597-ab1f-babe98bba294",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_genres_votes_pairs(r):\n",
    "  \"\"\"\n",
    "  Creates pairs of genres combinations with the number of votes.\n",
    "\n",
    "  Args:\n",
    "    r (dict): A dictionary with genres and numVotes.\n",
    "\n",
    "  Returns:\n",
    "    list: A list with tuples of sorted genre combination and the number of votes.\n",
    "          Returns an empty list if there is no genres or numVotes is None.\n",
    "  \"\"\"\n",
    "\n",
    "  if r[\"genres\"] and r[\"numVotes\"] is not None:\n",
    "    # sorting the list will apply determinism in the combinations\n",
    "    genres_sorted_list = sorted(r[\"genres\"].split(','))\n",
    "    genre_combination = ', '.join(genres_sorted_list)\n",
    "    return [(genre_combination, r[\"numVotes\"])]\n",
    "\n",
    "  return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba47cc28-b346-49ea-8686-9ced075e4ff6",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# getting the rating of each movie by 'tconst'\n",
    "movies_ratings_df = title_basics_df \\\n",
    "  .filter(F.col(\"titleType\") == \"movie\") \\\n",
    "  .join(title_ratings_df, \"tconst\", \"left\")\n",
    "# convert to RDD\n",
    "movies_ratings_rdd = movies_ratings_df.rdd\n",
    "# sort combinations of genres by popularity (= number of votes)\n",
    "most_popular_genres_combinations = movies_ratings_rdd \\\n",
    "  .flatMap(create_genres_votes_pairs) \\\n",
    "  .reduceByKey(lambda a, b: a + b) \\\n",
    "  .sortBy(lambda x: x[1], ascending=False) \\\n",
    "  .take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a6796a1-7a67-49df-b51c-d0b03d9991aa",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Action, Adventure, Sci-Fi', 54358980)]\n"
     ]
    }
   ],
   "source": [
    "print(most_popular_genres_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0abc7e28-0f21-4db1-88b2-a7cb261f7af9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q8 ANSWER: Most popular combination of genres, as measures by number of reviews: 'Action, Adventure, Sci-Fi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d01f24fc-3580-452b-aa71-403b80a48ee7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Q9** Movies can have multiple genres. Considering only titles of the type 'movie', and movies with more than 400 ratings, what is the combination of genres that has the highest **average movie rating** (you can average the movie rating for each movie in that genre combination). Hint: paired RDD's will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb41d78-a501-41d6-bb23-81487db1f7f1",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_genre_reviews_pairs(r):\n",
    "  \"\"\"\n",
    "  Creates pairs of genres combinations with the number of votes.\n",
    "\n",
    "  Args:\n",
    "    r (dict): A dictionary with genres and numVotes.\n",
    "\n",
    "  Returns:\n",
    "    list: A list with tuples of sorted genre combination and the number of votes.\n",
    "          Returns an empty list if there is no genres or numVotes is None.\n",
    "  \"\"\"  \n",
    "\n",
    "  if r['genres'] and r['averageRating'] is not None:\n",
    "    genres_sorted_list = sorted(r['genres'].split(','))\n",
    "    genre_combination = ', '.join(genres_sorted_list)\n",
    "    return [(genre_combination, (r['averageRating'], 1))]\n",
    "\n",
    "  return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eabf7d1-5886-44d5-8c65-597f740ebff1",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Filter movies with more than 400 votes, join title basics with ratings data\n",
    "movies_ratings_df = title_basics_df \\\n",
    "  .join(title_ratings_df, \"tconst\", \"inner\") \\\n",
    "  .filter((F.col(\"titleType\") == \"movie\") & (F.col(\"numVotes\") > 400))\n",
    "# convert to RDD\n",
    "movies_ratings_rdd = movies_ratings_df.rdd\n",
    "# sort combinations of genres by highest average rating\n",
    "highest_combination = movies_ratings_rdd \\\n",
    "  .flatMap(create_genre_reviews_pairs) \\\n",
    "  .reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1])) \\\n",
    "  .mapValues(lambda x: x[0] / x[1]) \\\n",
    "  .sortBy(lambda x: x[1], ascending=False) \\\n",
    "  .take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a1d7b03-1bf0-450e-a3f4-7357e2c553a7",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Action, Documentary, Mystery', 8.3)]\n"
     ]
    }
   ],
   "source": [
    "print(highest_combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e48af46-8d71-4a36-8001-fbd3d99d1be1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q9 ANSWER: Most popular combination of genres with the highest average movie rating:'Action, Documentary, Mystery'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82f2eccb-2c6b-46b4-97b4-4865ec799d81",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Q10** Movies can have multiple genres. What is **the individual genre** which is the most popular as meaured by number of votes. Votes for multiple genres count towards each genre listed. Hint: flatmap and pairedRDD's will be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90642194-9631-461f-96dd-dc01b6761ca2",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_genre_votes_pairs(r):\n",
    "  \"\"\"\n",
    "  Creates pairs of genre with the number of votes.\n",
    "\n",
    "  Args:\n",
    "    r (dict): A dictionary with genres and numVotes as keys.\n",
    "\n",
    "  Returns:\n",
    "    list: A list with tuples of genre and the number of votes.\n",
    "          Returns an empty list if there is no genres or numVotes is None.\n",
    "  \"\"\"  \n",
    "\n",
    "  if r['genres'] and r['numVotes'] is not None:\n",
    "    return [(genre, r['numVotes']) for genre in r['genres'].split(',')]\n",
    "  \n",
    "  return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa04789-d020-437b-af38-f3113e624626",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# filter only the movies\n",
    "movies_ratings_filtered_df = movies_ratings_df \\\n",
    "  .filter(F.col(\"titleType\") == \"movie\")\n",
    "\n",
    "# convert to RDD \n",
    "movies_ratings_rdd = movies_ratings_filtered_df.rdd\n",
    "# sort genres (individually) by number of votes\n",
    "most_popular_genre = movies_ratings_rdd \\\n",
    "  .flatMap(create_genre_votes_pairs) \\\n",
    "  .reduceByKey(lambda a, b: a + b) \\\n",
    "  .sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ad2b433-d03d-4a8d-960f-b29b16d8cec0",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Drama', 564014416)]\n"
     ]
    }
   ],
   "source": [
    "print(most_popular_genre.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "439c78b1-670d-4f14-a1c9-d266c53d7eb1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q10 ANSWER: Most popular (individual) genre, as measures by number of votes: 'Drama'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c34dffe-aaee-419a-a24a-91c5b590760f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Engineering the perfect cast\n",
    "We have created a number of potential features for predicting the rating of a movie based on its cast. Use sparkML to build a simple linear model to predict the rating of a movie based on the following features:\n",
    "\n",
    "1. The total number of movies in which the actors / actresses have acted (based on Q3)\n",
    "1. The average pagerank of the cast in each movie (based on Q5)\n",
    "1. The average outDegree of the cast in each movie (based on Q6)\n",
    "1. The average value for for the cast of degrees of Kevin Bacon (based on Q7).\n",
    "\n",
    "You will need to create a dataframe with the required features and label. Use a pipeline to create the vectors required by sparkML and apply the model. Remember to split your dataset, leave 30% of the data for testing, when splitting your data use the option seed=0.\n",
    "\n",
    "**Q11** Provide the coefficients of the regression and the accuracy of your model on that test dataset according to RSME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd68fd11-2f64-42a7-bb5a-398e89d3164b",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Q3-> actors_raking_df\n",
    "# Q5-> pagerank_results\n",
    "# Q6-> out_degrees\n",
    "# Q7-> distances_df\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dda38ef-c8ea-4fe0-bf1b-8597c1cdc501",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, predictions):\n",
    "  \"\"\"\n",
    "  It runs the regression evaluator using RMSE as the metric,\n",
    "  then shows the RMSE, and the coefficients.\n",
    "\n",
    "  Args:\n",
    "    model (object): The model to be evaluated\n",
    "    predictions (object): The predictions\n",
    "  \"\"\"\n",
    "\n",
    "  evaluator = RegressionEvaluator(\n",
    "    labelCol=\"averageRating\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    "  )\n",
    "\n",
    "  results = {\n",
    "    \"rmse\": evaluator.evaluate(predictions),\n",
    "  }\n",
    "  \n",
    "  if hasattr(model.stages[-1], 'coefficients'):\n",
    "    results.update({\n",
    "      \"coefficients\": model.stages[-1].coefficients,\n",
    "      \"intercept\": model.stages[-1].intercept\n",
    "    })\n",
    "\n",
    "  display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dacf278f-fb63-46b6-881f-bd9a6af1901f",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_pipeline(features, model):\n",
    "  \"\"\"\n",
    "  It buils a pipeline with an imputer, assembler, and scaler\n",
    "\n",
    "  Args:\n",
    "    features (list): The features\n",
    "    model (object): The model to be used\n",
    "\n",
    "  Returns:\n",
    "    pipeline: a new pipeline\n",
    "  \"\"\"\n",
    "\n",
    "  # impute missing values with 0 yields better results than mode, median or mean\n",
    "  imputer = Imputer(missingValue=0, inputCols=features, outputCols=features)\n",
    "  assembler = VectorAssembler(inputCols=features, outputCol=\"assembled_features\")\n",
    "  scaler = MinMaxScaler(inputCol=\"assembled_features\", outputCol=\"features\")\n",
    "\n",
    "  return Pipeline(stages=[imputer, assembler, scaler, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e355d80-ea15-43b1-80d1-03eb2e1caa87",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# feature 1\n",
    "movies_count_df = actors_raking_df \\\n",
    "  .select(\"nconst\", \"movie_count\")\n",
    "# feature 2\n",
    "pagerank_df = pagerank_results.vertices \\\n",
    "  .select(\"id\", \"pagerank\") \\\n",
    "  .withColumnRenamed(\"id\", \"nconst\")\n",
    "# feature 3\n",
    "out_degrees_df = out_degrees \\\n",
    "  .select(\"id\", \"outDegree\") \\\n",
    "  .withColumnRenamed(\"id\", \"nconst\")\n",
    "# feature 4\n",
    "distance_from_kevin_df = distances_df \\\n",
    "  .select(\"actor_id\", \"distance\") \\\n",
    "  .withColumnRenamed(\"actor_id\", \"nconst\")\n",
    "# aggregating features in a dataframe\n",
    "features_df = network_filtered_df \\\n",
    "  .join(movies_count_df, \"nconst\", \"left\") \\\n",
    "  .join(pagerank_df, \"nconst\", \"left\") \\\n",
    "  .join(out_degrees_df, \"nconst\", \"left\") \\\n",
    "  .join(distance_from_kevin_df, \"nconst\", \"left\") \\\n",
    "  .groupBy(\"tconst\") \\\n",
    "  .agg(\n",
    "    F.avg(\"movie_count\").alias(\"averageMovieCount\"),\n",
    "    F.avg(\"pagerank\").alias(\"averagePagerank\"),\n",
    "    F.avg(\"outDegree\").alias(\"averageOutDegree\"),\n",
    "    F.avg(\"distance\").alias(\"averageDistance\")\n",
    "  )\n",
    "# this variable containes the names of the features\n",
    "features = [\"averageMovieCount\", \"averagePagerank\", \"averageOutDegree\", \"averageDistance\"]\n",
    "# select features and label\n",
    "features_label_df = features_df \\\n",
    "  .join(title_ratings_df, \"tconst\") \\\n",
    "  .select(*features, \"averageRating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b671b8ef-1267-44f3-88ce-4e3d4e109dd9",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+----------------+---------------+-------------+\n",
      "|averageMovieCount|    averagePagerank|averageOutDegree|averageDistance|averageRating|\n",
      "+-----------------+-------------------+----------------+---------------+-------------+\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|          2.4|\n",
      "+-----------------+-------------------+----------------+---------------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data split\n",
    "(train_df, test_df) = features_label_df.randomSplit([0.7, 0.3], seed=0)\n",
    "train_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85d42744-ddf5-4c09-b075-00bebe77f182",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = get_pipeline(features, LinearRegression(featuresCol=\"assembled_features\", labelCol=\"averageRating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19fcd2ab-fec4-4f04-bab7-317e88bd668d",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0624b421-6359-4b37-ab3f-57541b87da63",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 1.3164892185154347,\n",
       " 'coefficients': DenseVector([-0.0002, -0.1115, 0.0032, 0.0106]),\n",
       " 'intercept': 5.970414512920328}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.transform(test_df) # making the predictions\n",
    "evaluate_model(model, predictions) #evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26c50983-008f-4563-85b2-d39ff4dfef10",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q11 ANSWER:\n",
    "- features: [\"averageMovieCount\", \"averagePagerank\", \"averageOutDegree\", \"averageDistance\"]\n",
    "- intercept: 5.970414512920328\n",
    "- coefficients: DenseVector([-0.0002, -0.1115, 0.0032, 0.0106])\n",
    "- accuracy of the model according to RMSE: 1.3164892185154347"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "401ea2c4-481b-449f-b2d0-5c482f27d0c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Q12** What score would your model predict for the 1997 movie Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77c38502-f67e-45d2-bc14-9ebb79b10295",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+-----------------+------------------+\n",
      "| averageMovieCount|   averagePagerank| averageOutDegree|   averageDistance|\n",
      "+------------------+------------------+-----------------+------------------+\n",
      "|39.127560454389666|3.0995923148847213|95.95603762529855|3.3580300899388984|\n",
      "+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the dataframe to include only the 1997 movie Titanic\n",
    "titanic_df = title_basics_df \\\n",
    "  .filter(F.col(\"primaryTitle\") == \"Titanic\") \\\n",
    "  .filter(F.col(\"startYear\") == 1997) \\\n",
    "  .filter(F.col(\"titleType\") == \"movie\")\n",
    "# filter the cast dataframe to include only the cast of Titanic\n",
    "titanic_cast = network_filtered_df \\\n",
    "  .filter(F.col(\"tconst\") == titanic_df[\"tconst\"]) \\\n",
    "  .select(\"nconst\")\n",
    "# join Titanic cast dataframe with other feature dataframes\n",
    "titanic_features_df = titanic_cast \\\n",
    "  .join(movies_count_df, \"nconst\", \"left\") \\\n",
    "  .join(pagerank_df, \"nconst\", \"left\") \\\n",
    "  .join(out_degrees_df, \"nconst\", \"left\") \\\n",
    "  .join(distance_from_kevin_df, \"nconst\", \"left\") \\\n",
    "  .agg(\n",
    "    F.avg(\"movie_count\").alias(\"averageMovieCount\"),\n",
    "    F.avg(\"pagerank\").alias(\"averagePagerank\"),\n",
    "    F.avg(\"outDegree\").alias(\"averageOutDegree\"),\n",
    "    F.avg(\"distance\").alias(\"averageDistance\")\n",
    "  )\n",
    "# display first row\n",
    "titanic_features_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55971099-85ec-47ef-b988-53d571e9ba4b",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|averageRating|\n",
      "+-------------+\n",
      "|          7.9|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# actual value of avg rating on titanic\n",
    "titanic_df.join(movies_ratings_df, on=\"tconst\", how=\"left\").select(\"averageRating\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8adf96f-991d-47a5-baf3-c75c0cb34332",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.9564151871319995\n"
     ]
    }
   ],
   "source": [
    "# modeling & prediction\n",
    "titanic_prediction = model \\\n",
    "  .transform(titanic_features_df) \\\n",
    "  .select(\"prediction\") \\\n",
    "  .first()\n",
    "\n",
    "print(titanic_prediction[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f8b2810-3dda-47d4-8486-2832e98ee12c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q12 ANSWER: Predicted average score for the 1997 movie Titanic: 5.9564151871319995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8489978a-4c37-452f-84c9-5e24498998c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Q13** Create dummy variables for each of the top 10 movie genres for Q10. These variable should have a value of 1 if the movie was rated with that genre and 0 otherwise. For example the 1997 movie Titanic should have a 1 in the dummy variable column for Romance, and a 1 in the dummy variable column for Drama, and 0's in all the other dummy variable columns.\n",
    "\n",
    "Does adding these variable to the regression improve your results? What is the new RMSE and predicted rating for the 1997 movie Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f5ad2dd-4e9f-4021-9d56-8231a60e4bbb",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## Create Dummy Variables\n",
    "# identify the top 10 genres from Q10:most_popular_genre \n",
    "top_ten_genres = [genre for genre, _ in most_popular_genre.take(10)]\n",
    "# create dummy variables for each of the top genres\n",
    "for genre in top_ten_genres:\n",
    "  movies_ratings_filtered_df = movies_ratings_filtered_df \\\n",
    "    .withColumn(genre, F.when(movies_ratings_filtered_df.genres.contains(genre), 1).otherwise(0))\n",
    "# include dummy variables in the dataframe\n",
    "features_with_dummies_df = features_df \\\n",
    "  .join(movies_ratings_filtered_df.select(\"tconst\", *top_ten_genres), \"tconst\")\n",
    "# combine original columns with dummy\n",
    "features_with_dummies = features + top_ten_genres\n",
    "# include target\n",
    "features_with_dummies_label_df = features_with_dummies_df \\\n",
    "  .join(title_ratings_df, \"tconst\") \\\n",
    "  .select(*features_with_dummies, \"averageRating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6a1b1ac-ea6b-4605-96d8-4aeed69f0e3c",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+----------------+---------------+-----+------+------+---------+-----+--------+------+-------+-------+------+-------------+\n",
      "|averageMovieCount|    averagePagerank|averageOutDegree|averageDistance|Drama|Action|Comedy|Adventure|Crime|Thriller|Sci-Fi|Romance|Mystery|Horror|averageRating|\n",
      "+-----------------+-------------------+----------------+---------------+-----+------+------+---------+-----+--------+------+-------+-------+------+-------------+\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|    0|     0|     0|        0|    0|       0|     0|      0|      0|     0|          7.3|\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|    0|     0|     0|        0|    0|       0|     0|      0|      0|     0|          7.5|\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|    0|     0|     0|        0|    0|       0|     0|      0|      0|     0|          7.7|\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|    0|     0|     0|        1|    0|       0|     1|      0|      0|     0|          3.6|\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|    0|     0|     1|        0|    0|       0|     0|      0|      0|     0|          6.8|\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|    1|     0|     0|        0|    0|       0|     0|      0|      0|     0|          6.1|\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|    1|     0|     0|        0|    0|       0|     0|      0|      0|     0|          7.4|\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|    1|     0|     0|        0|    0|       0|     0|      0|      0|     0|          7.6|\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|    1|     0|     0|        0|    0|       0|     0|      0|      0|     1|          5.9|\n",
      "|              1.0|0.10761500911483049|            NULL|           20.0|    1|     0|     0|        0|    0|       0|     0|      0|      1|     0|          5.2|\n",
      "+-----------------+-------------------+----------------+---------------+-----+------+------+---------+-----+--------+------+-------+-------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "(train_df, test_df) = features_with_dummies_label_df.randomSplit([0.7, 0.3], seed=0)\n",
    "train_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e54c4c15-b3ee-4dda-adc9-22c6c12cd8e0",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## Regression with dummies\n",
    "pipeline = get_pipeline(features_with_dummies, LinearRegression(featuresCol=\"assembled_features\", labelCol=\"averageRating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eafa45bd-20c3-4553-960a-c79be0a4dfc0",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model_with_dummies = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e005b7f9-ef69-4652-b514-c8020d34f448",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 1.2066880758555962,\n",
       " 'coefficients': DenseVector([-0.0, -0.1842, 0.0064, -0.0237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " 'intercept': 6.003869947291806}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# new RMSE\n",
    "predictions = model_with_dummies.transform(test_df)\n",
    "evaluate_model(model_with_dummies, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c5303bf-b282-49e5-90d6-620a0a431e85",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+-----------------+------------------+-----+------+------+---------+-----+--------+------+-------+-------+------+\n",
      "| averageMovieCount|  averagePagerank| averageOutDegree|   averageDistance|Drama|Action|Comedy|Adventure|Crime|Thriller|Sci-Fi|Romance|Mystery|Horror|\n",
      "+------------------+-----------------+-----------------+------------------+-----+------+------+---------+-----+--------+------+-------+-------+------+\n",
      "|39.127560454389666|3.099592314884722|95.95603762529855|3.3580300899388984|    1|     0|     0|        0|    0|       0|     0|      1|      0|     0|\n",
      "+------------------+-----------------+-----------------+------------------+-----+------+------+---------+-----+--------+------+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## new predicted rating for the 1997 movie Titanic\n",
    "for genre in top_ten_genres:\n",
    "  titanic_df = titanic_df \\\n",
    "    .withColumn(genre, F.when(titanic_df.genres.contains(genre), 1).otherwise(0))\n",
    "# define features for the top 10 genres\n",
    "titanic_features_df = titanic_features_df \\\n",
    "  .crossJoin(titanic_df.select(*top_ten_genres))\n",
    "\n",
    "titanic_features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e1194dd-e14b-44f5-b37e-9557aa352d22",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.967223129539539\n"
     ]
    }
   ],
   "source": [
    "titanic_prediction = model_with_dummies \\\n",
    "  .transform(titanic_features_df) \\\n",
    "  .select(\"prediction\") \\\n",
    "  .first()\n",
    "\n",
    "print(titanic_prediction[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "267d9a39-aa0f-4596-a684-b66de4c96c0f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q13 Answer:\n",
    "Yes, it helped improve the results a _little_ bit. The new *RMSE* is 1.20 (was 1.31), and the new *predicted* value for 1997 Titanic movie is 5.96 (was 5.95)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b851cfc5-8a54-40f5-b720-c9c703f2313c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Q14 - Open Question**: Improve your model by testing different machine learning algorithms, using hyperparameter tuning on these algorithms, changing the included features. What is the RMSE of you final model and what rating does it predict for the 1997 movie Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2613db8-3331-4fcb-b400-66a81d7bdfc2",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "888bcc87-5e10-4617-b71e-0483eed29400",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Gradient Boosted Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f51618c-40b3-4626-a115-f7b81ed80cc3",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = get_pipeline(features_with_dummies, GBTRegressor(featuresCol=\"features\", labelCol=\"averageRating\", maxDepth=20, seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "df8f5c47-1046-4fff-abb6-e56f62cb1a45",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "gbt_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fd92d34-995e-4ed3-a9ae-5bc9482f6f89",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 1.0274561282609307}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = gbt_model.transform(test_df)\n",
    "evaluate_model(gbt_model, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d842413-4b65-4d61-be8a-89ac251601b0",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.544688111083342\n"
     ]
    }
   ],
   "source": [
    "titanic_prediction = gbt_model \\\n",
    "  .transform(titanic_features_df) \\\n",
    "  .select(\"prediction\") \\\n",
    "  .first()\n",
    "\n",
    "print(titanic_prediction[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c079b6ea-f6d7-415c-8013-26171e42b47c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d89871-314e-4af0-a9d0-c7add3d59167",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = get_pipeline(features_with_dummies, RandomForestRegressor(featuresCol=\"features\", labelCol=\"averageRating\", numTrees=5, maxDepth=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ed91c55-5a7b-4a7f-827e-e74fd7884670",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "rfr_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77a0799a-55ca-4ced-9718-d056955f3e62",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 1.2160554472690757}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.transform(test_df)\n",
    "evaluate_model(rfr_model, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e38fc7a-d084-4d18-ab73-1e8a6ed20691",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.317666605896088\n"
     ]
    }
   ],
   "source": [
    "titanic_prediction = rfr_model \\\n",
    "  .transform(titanic_features_df) \\\n",
    "  .select(\"prediction\") \\\n",
    "  .first()\n",
    "\n",
    "print(titanic_prediction[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2d7bc3e-f218-48e8-bbb4-c58961d8e42f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Random Forest Regressor with Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ae91c67-9816-4c9f-9fb8-b075d68fa49e",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(featuresCol=\"features\", labelCol=\"averageRating\")\n",
    "pipeline = get_pipeline(features_with_dummies, rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c29287e2-3430-441a-b00f-7ad9e8d0147a",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder()\n",
    "  .addGrid(rfr.numTrees, [10, 20, 30])\n",
    "  .addGrid(rfr.maxDepth, [10, 20, 30])\n",
    "  .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceb1379b-72f3-45ef-9935-87a825f05c90",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"averageRating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "cross_validator = CrossValidator(\n",
    "  estimator=pipeline,\n",
    "  estimatorParamMaps=paramGrid,\n",
    "  evaluator=evaluator,\n",
    "  numFolds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8254e971-c090-4df6-be4c-35668487e133",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cv_model = cross_validator.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88080dd2-6b55-4108-9f4d-c69005ce5700",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1546649159103306\n"
     ]
    }
   ],
   "source": [
    "predictions = cv_model.transform(test_df)\n",
    "print(evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65fca3e1-d455-4de2-b3c5-adc3fd0e9ec8",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.37429394448341\n"
     ]
    }
   ],
   "source": [
    "titanic_prediction = cv_model \\\n",
    "  .transform(titanic_features_df) \\\n",
    "  .select(\"prediction\") \\\n",
    "  .first()\n",
    "\n",
    "print(titanic_prediction[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03271788-b030-4dec-bd6a-a8ec026eee38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Changing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a687477d-06f4-4bc2-8636-02f85b4b6306",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "features_with_dummies_numvotes = features_with_dummies + [\"numVotes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40bc34e1-18c0-40f2-a763-a1124e56aead",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "features_with_dummies_label_df = features_with_dummies_df \\\n",
    "  .join(title_ratings_df, \"tconst\") \\\n",
    "  .select(*features_with_dummies_numvotes, \"averageRating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c26e36fd-2b5f-4df0-990e-933b20c8f3d9",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = get_pipeline(features_with_dummies_numvotes, RandomForestRegressor(featuresCol=\"features\", labelCol=\"averageRating\", numTrees=5, maxDepth=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17f9da40-c313-4fdb-9735-20e316518603",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "(train_df, test_df) = features_with_dummies_label_df.randomSplit([0.7, 0.3], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "876bde22-09a3-4904-b411-7687dbb0d094",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "rfr_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16232ed1-fa27-44e8-b028-64dc0b0b1a42",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1512289822609025\n"
     ]
    }
   ],
   "source": [
    "predictions = rfr_model.transform(test_df)\n",
    "print(evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e746cd26-1524-4c0b-94d6-86ea63d948d4",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+-----------------+------------------+-----+------+------+---------+-----+--------+------+-------+-------+------+--------+\n",
      "| averageMovieCount|   averagePagerank| averageOutDegree|   averageDistance|Drama|Action|Comedy|Adventure|Crime|Thriller|Sci-Fi|Romance|Mystery|Horror|numVotes|\n",
      "+------------------+------------------+-----------------+------------------+-----+------+------+---------+-----+--------+------+-------+-------+------+--------+\n",
      "|39.127560454389666|3.0995923148847213|95.95603762529855|3.3580300899388984|    1|     0|     0|        0|    0|       0|     0|      1|      0|     0| 1286967|\n",
      "+------------------+------------------+-----------------+------------------+-----+------+------+---------+-----+--------+------+-------+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_features_df = titanic_features_df \\\n",
    "  .crossJoin(titanic_df.join(movies_ratings_df, on=\"tconst\", how=\"left\").select(\"numVotes\"))\n",
    "\n",
    "titanic_features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cd36812-4971-438d-85e7-8f0b65ba21b5",
     "showTitle": false,
     "title": ""
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.081851678361451\n"
     ]
    }
   ],
   "source": [
    "titanic_prediction = rfr_model \\\n",
    "  .transform(titanic_features_df) \\\n",
    "  .select(\"prediction\") \\\n",
    "  .first()\n",
    "\n",
    "print(titanic_prediction[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3a42944-d12d-409b-8343-d01547535dd4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Q14 Answer:\n",
    "\n",
    "Our best model is **GBTRegressor**, which *predicted* 7.54 (7.9 y_true) for the 1997 Titanic movie, while a 1.02 *RMSE*."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "practical_exam_2024",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  },
  "name": "Exam BDA AA 2020",
  "notebookId": 3446163725308994
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
